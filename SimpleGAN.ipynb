{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYY3isjI7qFC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cab0f9cd-80ce-40f0-aa0b-2bc7b75f1337"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "matplotlib_is_available = True\n",
        "try:\n",
        "  from matplotlib import pyplot as plt\n",
        "except ImportError:\n",
        "  print(\"Will skip plotting; matplotlib is not available.\")\n",
        "  matplotlib_is_available = False\n",
        "\n",
        "# Data params\n",
        "data_mean = 4\n",
        "data_stddev = 1.25\n",
        "\n",
        "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
        "(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
        "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
        "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
        "#(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
        "\n",
        "print(\"Using data [%s]\" % (name))\n",
        "\n",
        "# ##### DATA: Target data and generator input data\n",
        "\n",
        "def get_distribution_sampler(mu, sigma):\n",
        "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
        "\n",
        "def get_generator_input_sampler():\n",
        "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian\n",
        "\n",
        "# ##### MODELS: Generator model and discriminator model\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, f):\n",
        "        super(Generator, self).__init__()\n",
        "        self.map1 = nn.Linear(input_size, hidden_size)\n",
        "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.map3 = nn.Linear(hidden_size, output_size)\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.map1(x)\n",
        "        x = self.f(x)\n",
        "        x = self.map2(x)\n",
        "        x = self.f(x)\n",
        "        x = self.map3(x)\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, f):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.map1 = nn.Linear(input_size, hidden_size)\n",
        "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.map3 = nn.Linear(hidden_size, output_size)\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.f(self.map1(x))\n",
        "        x = self.f(self.map2(x))\n",
        "        return self.f(self.map3(x))\n",
        "\n",
        "def extract(v):\n",
        "    return v.data.storage().tolist()\n",
        "\n",
        "def stats(d):\n",
        "    return [np.mean(d), np.std(d)]\n",
        "\n",
        "def train():\n",
        "    # Model parameters\n",
        "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
        "    g_hidden_size = 5     # Generator complexity\n",
        "    g_output_size = 1     # Size of generated output vector\n",
        "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
        "    d_hidden_size = 10    # Discriminator complexity\n",
        "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
        "    minibatch_size = d_input_size\n",
        "\n",
        "    d_learning_rate = 1e-3\n",
        "    g_learning_rate = 1e-3\n",
        "    sgd_momentum = 0.9\n",
        "\n",
        "    num_epochs = 5000\n",
        "    print_interval = 100\n",
        "    d_steps = 20\n",
        "    g_steps = 20\n",
        "\n",
        "    dfe, dre, ge = 0, 0, 0\n",
        "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
        "\n",
        "    discriminator_activation_function = torch.sigmoid\n",
        "    generator_activation_function = torch.tanh\n",
        "\n",
        "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
        "    gi_sampler = get_generator_input_sampler()\n",
        "    G = Generator(input_size=g_input_size,\n",
        "                  hidden_size=g_hidden_size,\n",
        "                  output_size=g_output_size,\n",
        "                  f=generator_activation_function)\n",
        "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
        "                      hidden_size=d_hidden_size,\n",
        "                      output_size=d_output_size,\n",
        "                      f=discriminator_activation_function)\n",
        "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
        "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
        "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for d_index in range(d_steps):\n",
        "            # 1. Train D on real+fake\n",
        "            D.zero_grad()\n",
        "\n",
        "            #  1A: Train D on real\n",
        "            d_real_data = Variable(d_sampler(d_input_size))\n",
        "            d_real_decision = D(preprocess(d_real_data))\n",
        "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
        "            d_real_error.backward() # compute/store gradients, but don't change params\n",
        "\n",
        "            #  1B: Train D on fake\n",
        "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
        "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
        "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
        "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
        "            d_fake_error.backward()\n",
        "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
        "\n",
        "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
        "\n",
        "        for g_index in range(g_steps):\n",
        "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
        "            G.zero_grad()\n",
        "\n",
        "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
        "            g_fake_data = G(gen_input)\n",
        "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
        "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
        "\n",
        "            g_error.backward()\n",
        "            g_optimizer.step()  # Only optimizes G's parameters\n",
        "            ge = extract(g_error)[0]\n",
        "\n",
        "        if epoch % print_interval == 0:\n",
        "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
        "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
        "\n",
        "    if matplotlib_is_available:\n",
        "        print(\"Plotting the generated distribution...\")\n",
        "        values = extract(g_fake_data)\n",
        "        print(\" Values: %s\" % (str(values)))\n",
        "        plt.hist(values, bins=50)\n",
        "        plt.xlabel('Value')\n",
        "        plt.ylabel('Count')\n",
        "        plt.title('Histogram of Generated Distribution')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "train()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using data [Raw data]\n",
            "Epoch 0: D (0.9864380359649658 real_err, 0.45874738693237305 fake_err) G (0.9947319626808167 err); Real Dist ([4.0555230234861375, 1.2693943869712014]),  Fake Dist ([0.1543886011838913, 0.003350787236773957]) \n",
            "Epoch 100: D (0.6608986854553223 real_err, 0.6988507509231567 fake_err) G (0.6868945956230164 err); Real Dist ([3.9696521291732787, 1.2695658216640817]),  Fake Dist ([3.838780704021454, 0.10599004477734628]) \n",
            "Epoch 200: D (0.6906707882881165 real_err, 0.6919502019882202 fake_err) G (0.6951128840446472 err); Real Dist ([3.980536941945553, 1.3026780419561934]),  Fake Dist ([3.7846190633773804, 0.11764059234815351]) \n",
            "Epoch 300: D (0.6987354159355164 real_err, 0.7014794945716858 fake_err) G (0.6826778054237366 err); Real Dist ([4.055632130503654, 1.2945836012500518]),  Fake Dist ([3.7929626784324646, 0.11215011018685501]) \n",
            "Epoch 400: D (0.6888530850410461 real_err, 0.6884615421295166 fake_err) G (0.6948471069335938 err); Real Dist ([4.130486733317375, 1.2199971413477109]),  Fake Dist ([3.792270538330078, 0.11782254483317242]) \n",
            "Epoch 500: D (0.6947667598724365 real_err, 0.6833783984184265 fake_err) G (0.6941365003585815 err); Real Dist ([4.006399520158768, 1.2913950239325611]),  Fake Dist ([3.8038143091201784, 0.11459638009338714]) \n",
            "Epoch 600: D (0.6002458333969116 real_err, 0.6790325045585632 fake_err) G (0.7099572420120239 err); Real Dist ([4.05667607498169, 1.2389998565838114]),  Fake Dist ([3.845644679546356, 0.12003053848968553]) \n",
            "Epoch 700: D (0.7269588112831116 real_err, 0.6384286284446716 fake_err) G (0.7461225390434265 err); Real Dist ([3.983213526427746, 1.2189414130278737]),  Fake Dist ([3.796834619998932, 0.12487142602088078]) \n",
            "Epoch 800: D (0.7458848357200623 real_err, 0.6860131025314331 fake_err) G (0.7172147631645203 err); Real Dist ([3.9574274718761444, 1.2595115164097808]),  Fake Dist ([3.8485054550170896, 0.13902739526200691]) \n",
            "Epoch 900: D (0.4760254919528961 real_err, 0.7609142065048218 fake_err) G (0.6880050897598267 err); Real Dist ([3.949298810094595, 1.2701461771573481]),  Fake Dist ([3.967480344772339, 0.14484836697354397]) \n",
            "Epoch 1000: D (0.7554030418395996 real_err, 0.6556386351585388 fake_err) G (0.7287549376487732 err); Real Dist ([4.031574790656567, 1.2791595146722852]),  Fake Dist ([3.834571051597595, 0.16274378634385947]) \n",
            "Epoch 1100: D (0.6932516098022461 real_err, 0.6933274269104004 fake_err) G (0.6930396556854248 err); Real Dist ([4.097093620032072, 1.2611155945130585]),  Fake Dist ([4.029234621047974, 0.1775944349816668]) \n",
            "Epoch 1200: D (0.693152666091919 real_err, 0.6931548118591309 fake_err) G (0.6931416988372803 err); Real Dist ([4.095474927544593, 1.298932963207689]),  Fake Dist ([4.030521049499511, 0.17959125962832365]) \n",
            "Epoch 1300: D (0.6931610107421875 real_err, 0.6931352615356445 fake_err) G (0.6931579113006592 err); Real Dist ([3.981443775832653, 1.2256570888590328]),  Fake Dist ([3.8915673389434815, 0.18008061200316267]) \n",
            "Epoch 1400: D (0.6931533813476562 real_err, 0.6931265592575073 fake_err) G (0.6931650638580322 err); Real Dist ([3.953226277887821, 1.2879027182349476]),  Fake Dist ([3.935665644645691, 0.18877932162968677]) \n",
            "Epoch 1500: D (0.6931813955307007 real_err, 0.6931631565093994 fake_err) G (0.6931360960006714 err); Real Dist ([4.030622210815549, 1.2539381834386858]),  Fake Dist ([4.009100185394287, 0.17710239637012723]) \n",
            "Epoch 1600: D (0.6931418180465698 real_err, 0.6931536197662354 fake_err) G (0.6931400299072266 err); Real Dist ([4.050581830263138, 1.2970483315399393]),  Fake Dist ([4.024377751350403, 0.17941005021201498]) \n",
            "Epoch 1700: D (0.6931633949279785 real_err, 0.693148136138916 fake_err) G (0.6931396722793579 err); Real Dist ([4.042965357065201, 1.2810105640986318]),  Fake Dist ([4.035228686332703, 0.18610576548494778]) \n",
            "Epoch 1800: D (0.6932070255279541 real_err, 0.6931062936782837 fake_err) G (0.6931872367858887 err); Real Dist ([3.9326633076071738, 1.1879299796264533]),  Fake Dist ([4.065884690284729, 0.1814313616258952]) \n",
            "Epoch 1900: D (0.6673341989517212 real_err, 0.707304060459137 fake_err) G (0.6682742238044739 err); Real Dist ([4.006337391920388, 1.2670326063544515]),  Fake Dist ([3.4431058526039124, 0.2065273280454534]) \n",
            "Epoch 2000: D (0.69312584400177 real_err, 0.6931986808776855 fake_err) G (0.6931076049804688 err); Real Dist ([4.102551468133926, 1.3024347704360062]),  Fake Dist ([4.063731727600097, 0.20379196140767047]) \n",
            "Epoch 2100: D (0.6931262016296387 real_err, 0.6931459903717041 fake_err) G (0.6931533813476562 err); Real Dist ([4.102499803066253, 1.2545976226876867]),  Fake Dist ([4.0869622521400455, 0.21083947823946292]) \n",
            "Epoch 2200: D (0.6931784152984619 real_err, 0.6931548118591309 fake_err) G (0.6931447982788086 err); Real Dist ([3.89061684691906, 1.2802853410165398]),  Fake Dist ([3.9990274629592895, 0.21870952482712194]) \n",
            "Epoch 2300: D (0.6932053565979004 real_err, 0.6931521892547607 fake_err) G (0.6931407451629639 err); Real Dist ([3.8808760239481925, 1.297338698515305]),  Fake Dist ([4.021971720218659, 0.2156005117142203]) \n",
            "Epoch 2400: D (0.6931394338607788 real_err, 0.6931509971618652 fake_err) G (0.693145751953125 err); Real Dist ([4.0796236711740494, 1.221367444532432]),  Fake Dist ([4.028159435749054, 0.22238806152335017]) \n",
            "Epoch 2500: D (0.6931453943252563 real_err, 0.6931512355804443 fake_err) G (0.6931443214416504 err); Real Dist ([3.9969022566080095, 1.272662703044423]),  Fake Dist ([4.034585288047791, 0.21166808973433218]) \n",
            "Epoch 2600: D (0.6931474208831787 real_err, 0.6931530237197876 fake_err) G (0.6931425333023071 err); Real Dist ([4.057804631471634, 1.2465461270551244]),  Fake Dist ([4.052624792098999, 0.21240456094074167]) \n",
            "Epoch 2700: D (0.6931502819061279 real_err, 0.6931490898132324 fake_err) G (0.6931432485580444 err); Real Dist ([4.081788713693618, 1.2166722559031529]),  Fake Dist ([4.0284857053756715, 0.21613575609999325]) \n",
            "Epoch 2800: D (0.6931444406509399 real_err, 0.6931499242782593 fake_err) G (0.6931437253952026 err); Real Dist ([4.128483546853065, 1.2618679280771157]),  Fake Dist ([4.060238492012024, 0.21405163572788824]) \n",
            "Epoch 2900: D (0.6931540966033936 real_err, 0.693149209022522 fake_err) G (0.693144679069519 err); Real Dist ([3.9111767539978026, 1.2119220237209942]),  Fake Dist ([4.065422733306884, 0.2178580791706576]) \n",
            "Epoch 3000: D (0.6931467056274414 real_err, 0.6931493282318115 fake_err) G (0.6931465864181519 err); Real Dist ([4.02633229470253, 1.2287281555474459]),  Fake Dist ([4.069004391670227, 0.21099976123731018]) \n",
            "Epoch 3100: D (0.6931579113006592 real_err, 0.6931489706039429 fake_err) G (0.6931447982788086 err); Real Dist ([3.9466844528317453, 1.2082700296450577]),  Fake Dist ([4.080768896102906, 0.20544424131519476]) \n",
            "Epoch 3200: D (0.6931493282318115 real_err, 0.693149209022522 fake_err) G (0.6931451559066772 err); Real Dist ([3.9635868193507195, 1.1992334205756436]),  Fake Dist ([4.093004290580749, 0.20640371917504824]) \n",
            "Epoch 3300: D (0.6931518316268921 real_err, 0.6931487321853638 fake_err) G (0.6931461095809937 err); Real Dist ([4.061491018116474, 1.2314120053801871]),  Fake Dist ([4.0839235944747925, 0.20864255016632874]) \n",
            "Epoch 3400: D (0.6931507587432861 real_err, 0.6931487321853638 fake_err) G (0.6931456327438354 err); Real Dist ([3.9506894026994703, 1.2480303723059616]),  Fake Dist ([4.091828385829926, 0.21158039896654784]) \n",
            "Epoch 3500: D (0.6931556463241577 real_err, 0.6931486129760742 fake_err) G (0.6931451559066772 err); Real Dist ([3.976603448882699, 1.2331164420573908]),  Fake Dist ([4.080720170497894, 0.2135233006601583]) \n",
            "Epoch 3600: D (0.6931502819061279 real_err, 0.6931487321853638 fake_err) G (0.6931456327438354 err); Real Dist ([4.068018404603005, 1.2403354248793919]),  Fake Dist ([4.09416801071167, 0.20902382042345788]) \n",
            "Epoch 3700: D (0.693151593208313 real_err, 0.6931487321853638 fake_err) G (0.6931456327438354 err); Real Dist ([3.8762933573722838, 1.2228455097273365]),  Fake Dist ([4.107398725986481, 0.21021950739669762]) \n",
            "Epoch 3800: D (0.6931519508361816 real_err, 0.6931482553482056 fake_err) G (0.6931464672088623 err); Real Dist ([4.008722550075501, 1.284670802880232]),  Fake Dist ([4.081513435363769, 0.21783307868649074]) \n",
            "Epoch 3900: D (0.6931480169296265 real_err, 0.6931478977203369 fake_err) G (0.6931465864181519 err); Real Dist ([4.045397219598294, 1.267496774217138]),  Fake Dist ([4.093753975391388, 0.21026844646027876]) \n",
            "Epoch 4000: D (0.6931483745574951 real_err, 0.693148136138916 fake_err) G (0.6931461095809937 err); Real Dist ([3.9912842736840246, 1.207957752886827]),  Fake Dist ([4.1009662780761715, 0.21084446084820468]) \n",
            "Epoch 4100: D (0.6931490898132324 real_err, 0.6931480169296265 fake_err) G (0.6931464672088623 err); Real Dist ([4.049739052772522, 1.2982784361245876]),  Fake Dist ([4.1009704113006595, 0.20914932085659307]) \n",
            "Epoch 4200: D (0.6931494474411011 real_err, 0.6931476593017578 fake_err) G (0.6931463479995728 err); Real Dist ([3.9978907759785653, 1.2766708999659069]),  Fake Dist ([4.103781103134155, 0.21988326987298484]) \n",
            "Epoch 4300: D (0.6931483745574951 real_err, 0.6931482553482056 fake_err) G (0.6931464672088623 err); Real Dist ([4.063281719624996, 1.2836896838543685]),  Fake Dist ([4.105441625595093, 0.21235589755723547]) \n",
            "Epoch 4400: D (0.6931500434875488 real_err, 0.6931480169296265 fake_err) G (0.6931461095809937 err); Real Dist ([3.974012080311775, 1.1141226465456662]),  Fake Dist ([4.103708806037903, 0.22398518850037552]) \n",
            "Epoch 4500: D (0.6931511163711548 real_err, 0.6931480169296265 fake_err) G (0.6931463479995728 err); Real Dist ([3.9010080513954164, 1.2162840181622283]),  Fake Dist ([4.114867293357849, 0.20773594346199936]) \n",
            "Epoch 4600: D (0.6931486129760742 real_err, 0.6931480169296265 fake_err) G (0.6931461095809937 err); Real Dist ([3.9143798171281814, 1.194349137053177]),  Fake Dist ([4.108556784629822, 0.21382275974475368]) \n",
            "Epoch 4700: D (0.6931486129760742 real_err, 0.6931478977203369 fake_err) G (0.6931464672088623 err); Real Dist ([3.9581870839595794, 1.3279612287271059]),  Fake Dist ([4.106758633613587, 0.21643261422651452]) \n",
            "Epoch 4800: D (0.6931502819061279 real_err, 0.693148136138916 fake_err) G (0.6931463479995728 err); Real Dist ([4.030891982227564, 1.2408329870450312]),  Fake Dist ([4.114489236831665, 0.20972948319139698]) \n",
            "Epoch 4900: D (0.6931470632553101 real_err, 0.6931478977203369 fake_err) G (0.6931462287902832 err); Real Dist ([3.998203222155571, 1.234541524812343]),  Fake Dist ([4.086372994422913, 0.21398765722352686]) \n",
            "Plotting the generated distribution...\n",
            " Values: [4.203658103942871, 3.9402220249176025, 3.972341299057007, 3.8845698833465576, 3.6871025562286377, 4.216921806335449, 3.849801778793335, 4.1901655197143555, 4.3067474365234375, 4.109442710876465, 4.263873100280762, 4.201075553894043, 4.16462516784668, 4.318428039550781, 4.373976707458496, 4.351958274841309, 4.105423927307129, 3.9718520641326904, 4.133139610290527, 3.8785555362701416, 4.360424041748047, 4.022487640380859, 4.304008483886719, 3.761212110519409, 4.122891426086426, 4.212017059326172, 3.918631076812744, 4.205977439880371, 4.075072288513184, 4.3645219802856445, 4.321045875549316, 4.031838417053223, 4.356748580932617, 4.335082054138184, 3.9837183952331543, 3.6828181743621826, 4.0260210037231445, 4.383306503295898, 4.016899585723877, 4.314347267150879, 4.367259979248047, 4.116024017333984, 4.197577476501465, 4.106504440307617, 3.925170421600342, 4.2230024337768555, 3.9388835430145264, 4.103463172912598, 4.165600776672363, 4.160281181335449, 4.124171257019043, 4.115365028381348, 3.8515031337738037, 4.1064958572387695, 4.072671890258789, 4.1187334060668945, 4.375027656555176, 4.378603935241699, 4.332300186157227, 4.182222366333008, 3.6826560497283936, 4.344172477722168, 4.318076133728027, 3.855281114578247, 4.378005027770996, 4.28981876373291, 4.391092777252197, 4.384195804595947, 3.8186299800872803, 4.232876777648926, 3.7001686096191406, 4.322416305541992, 4.094554901123047, 3.8088090419769287, 4.38410758972168, 4.344573974609375, 3.8952882289886475, 4.218873977661133, 4.081241607666016, 3.8148181438446045, 4.254263877868652, 3.9501264095306396, 4.387479782104492, 3.990295171737671, 4.34678840637207, 3.6551241874694824, 3.9523935317993164, 3.9690473079681396, 4.214533805847168, 3.7393972873687744, 4.193906784057617, 4.378509521484375, 4.318249225616455, 4.342896938323975, 3.9495387077331543, 4.3817596435546875, 4.328575134277344, 4.183961391448975, 3.7186050415039062, 3.75427508354187, 4.252777099609375, 4.242880821228027, 4.04445219039917, 4.245448589324951, 3.9825825691223145, 4.364177703857422, 4.330317497253418, 4.279376983642578, 4.129406452178955, 4.3196892738342285, 4.3049774169921875, 3.7519123554229736, 3.859980344772339, 3.9389407634735107, 4.385475158691406, 3.6963770389556885, 4.327996253967285, 4.323410987854004, 3.906327486038208, 4.342370986938477, 4.3767476081848145, 4.384964942932129, 3.9858548641204834, 4.037764549255371, 4.032292366027832, 4.214212417602539, 4.31458854675293, 3.996135950088501, 4.084641456604004, 4.195798873901367, 4.361407279968262, 4.311868667602539, 4.229099273681641, 3.962027072906494, 4.333702087402344, 4.2920942306518555, 3.9164416790008545, 3.8126323223114014, 4.1190385818481445, 4.37264347076416, 4.287297248840332, 4.117208003997803, 4.358160972595215, 3.8609888553619385, 3.7009129524230957, 4.316608428955078, 3.8408753871917725, 4.3484930992126465, 4.096451759338379, 4.093177795410156, 4.380648612976074, 3.9827048778533936, 4.186912536621094, 4.01846170425415, 4.189671516418457, 3.8597018718719482, 3.6773455142974854, 4.141915321350098, 4.38441276550293, 3.9320285320281982, 3.7400665283203125, 4.224491596221924, 4.084165573120117, 3.712754011154175, 4.3353471755981445, 4.292808532714844, 4.106317520141602, 4.328676223754883, 4.384281158447266, 4.235675811767578, 4.078108787536621, 4.288551330566406, 4.153641700744629, 3.722738027572632, 4.335487365722656, 4.177539825439453, 3.9366824626922607, 4.067702293395996, 4.268170356750488, 4.239130973815918, 4.007401466369629, 4.011261940002441, 4.384428977966309, 3.8037302494049072, 3.936192035675049, 4.2864837646484375, 3.9951908588409424, 3.8705766201019287, 4.2903032302856445, 4.054355621337891, 4.322796821594238, 4.191924095153809, 4.3711442947387695, 4.312684059143066, 4.341730117797852, 3.8887252807617188, 3.67989444732666, 4.161256790161133, 4.301509857177734, 4.281015396118164, 4.255465984344482, 3.9155595302581787, 3.7623207569122314, 4.209376335144043, 4.276055335998535, 3.8277695178985596, 3.726203680038452, 3.924808979034424, 3.7673611640930176, 4.388424873352051, 4.389252662658691, 4.162416458129883, 4.095451354980469, 4.156792640686035, 4.221492767333984, 4.191570281982422, 4.086650848388672, 4.216075897216797, 3.8131630420684814, 4.389409065246582, 4.143967628479004, 3.9514729976654053, 4.256831169128418, 4.3799591064453125, 4.267644882202148, 4.31118106842041, 4.263310432434082, 4.281920433044434, 4.36095666885376, 4.295424461364746, 4.264551162719727, 3.6692898273468018, 3.686384439468384, 4.322779655456543, 4.313684463500977, 3.8369526863098145, 4.063442230224609, 4.346787452697754, 4.205877780914307, 4.258533954620361, 4.2392377853393555, 3.8879923820495605, 4.257685661315918, 4.113351821899414, 4.376659393310547, 3.7914183139801025, 4.320572376251221, 4.305393218994141, 4.056455612182617, 4.368247032165527, 3.8116095066070557, 4.105019569396973, 4.108921051025391, 3.8247063159942627, 3.822845935821533, 3.8077585697174072, 4.131218910217285, 4.214282989501953, 4.164665222167969, 3.9257514476776123, 4.124568939208984, 4.355906009674072, 4.341664791107178, 4.290681838989258, 4.325995445251465, 4.268239974975586, 4.172807693481445, 3.7214839458465576, 3.9719398021698, 4.063433647155762, 4.332399368286133, 3.9534313678741455, 4.255732536315918, 4.167854309082031, 4.292492866516113, 3.8735134601593018, 3.9363439083099365, 4.3807373046875, 4.0420379638671875, 4.321920394897461, 4.178096771240234, 4.22065544128418, 4.377538681030273, 4.325190544128418, 3.7583611011505127, 4.2203168869018555, 3.9641363620758057, 4.382011413574219, 4.349888801574707, 4.356776237487793, 3.707993268966675, 4.2731428146362305, 4.28950309753418, 4.351096153259277, 4.305631637573242, 4.367837905883789, 4.216739177703857, 4.2084736824035645, 4.148366928100586, 4.365296363830566, 3.7154476642608643, 3.7220442295074463, 4.3460283279418945, 4.159121513366699, 4.297114372253418, 4.301517486572266, 4.123926162719727, 4.320311546325684, 4.361814498901367, 4.225067138671875, 4.219914436340332, 4.158385276794434, 3.67486834526062, 4.257484436035156, 4.378535270690918, 4.057845115661621, 3.8504650592803955, 3.730556011199951, 4.345905303955078, 4.267032623291016, 4.319419860839844, 4.195527076721191, 3.9391732215881348, 3.9852545261383057, 3.821932077407837, 4.243669509887695, 4.315802574157715, 4.051232814788818, 3.940068483352661, 3.815282106399536, 4.373952388763428, 3.651153802871704, 3.8289761543273926, 3.899042844772339, 4.3330230712890625, 4.246497631072998, 3.7503111362457275, 4.077066421508789, 4.025364875793457, 4.286455154418945, 4.158400535583496, 4.128179550170898, 4.3159942626953125, 3.740110397338867, 4.335431098937988, 4.321598052978516, 4.321309566497803, 4.023075580596924, 4.325375556945801, 4.084088325500488, 4.319866180419922, 4.299897193908691, 3.834322214126587, 4.280601501464844, 3.9743854999542236, 4.249608993530273, 3.918774366378784, 4.030341148376465, 3.6809566020965576, 3.7384958267211914, 4.264348983764648, 4.270552635192871, 3.7401063442230225, 4.238490104675293, 3.688758611679077, 4.350399017333984, 3.8304202556610107, 3.6761748790740967, 4.368016242980957, 4.382424831390381, 4.229180335998535, 4.003047943115234, 4.363883018493652, 4.283251762390137, 4.371210098266602, 4.297364234924316, 4.33039665222168, 4.101712226867676, 4.105151176452637, 4.241560935974121, 4.305999755859375, 4.277202606201172, 4.355134010314941, 4.257647514343262, 4.385477066040039, 4.255066871643066, 4.078168869018555, 3.980778932571411, 4.299197196960449, 4.132315635681152, 4.324149131774902, 4.25522518157959, 4.216180801391602, 4.187698841094971, 4.183562278747559, 4.2802886962890625, 4.043980598449707, 3.7650697231292725, 4.243443965911865, 3.8225748538970947, 4.156826496124268, 3.7458436489105225, 3.999964952468872, 3.664207696914673, 4.330021858215332, 3.7363264560699463, 4.283123016357422, 3.80411958694458, 4.033872604370117, 4.353488922119141, 4.088881492614746, 4.295616149902344, 4.365619659423828, 4.35894250869751, 3.9005725383758545, 4.109193801879883, 4.142683029174805, 3.703512191772461, 4.30592155456543, 4.300921440124512, 4.275206565856934, 4.264984130859375, 3.937932014465332, 4.382568359375, 3.936575174331665, 4.377137184143066, 4.193576812744141, 3.6624042987823486, 4.304755210876465, 4.374543190002441, 4.185942649841309, 4.278072834014893, 4.307525634765625, 4.3593902587890625, 4.343335151672363, 3.9689271450042725, 4.273730278015137, 4.139240264892578, 4.154804229736328, 3.950972557067871, 4.360938549041748, 3.97680401802063, 4.265358924865723, 3.9729933738708496, 3.935343027114868, 4.2830610275268555, 4.165392875671387, 3.739478588104248, 3.9949967861175537, 4.197908401489258, 4.278814792633057, 4.360782623291016, 4.243062973022461, 3.7325222492218018, 4.324249267578125, 4.349230766296387, 4.243531227111816, 4.270700454711914, 4.024310111999512, 4.220909118652344, 3.7827820777893066, 3.9204273223876953, 3.9497106075286865, 4.347771644592285, 4.258039474487305, 3.9593000411987305, 4.160274505615234, 3.967617988586426, 3.9785518646240234, 4.324033260345459, 4.087555885314941, 3.912163019180298, 4.079154014587402, 4.349627494812012, 3.9935200214385986, 4.1978759765625, 4.36680269241333, 4.276117324829102, 3.8512706756591797, 4.3386406898498535, 4.325187683105469, 4.0404558181762695, 4.369980812072754, 4.314101219177246, 4.091609001159668, 4.227036476135254, 4.153416633605957, 3.953839063644409, 3.980787992477417, 4.067811489105225, 3.7659192085266113, 3.7297203540802, 4.211536407470703, 4.322899341583252, 4.221469879150391, 4.1902241706848145, 4.1396284103393555, 4.2654643058776855, 4.179020881652832, 4.37093448638916]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LImMRBB0Avb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}